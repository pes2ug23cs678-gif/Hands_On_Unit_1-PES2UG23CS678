Experiment        |  Model  |  Output obtained                                    |  Result  |  Why?                                                                                                                                                 |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Text generation   | BERT    | The future of Artificial Intelligence is....        | Failed   | Now, we are using the help of an Encoder-only transformner for text-generation, which would be done better with the help of a decoder-only transformer|
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Text generation   | BART    | The future of Artificial Intelligence isada..       | Success  | Here, we also have a decoder part present in the BART, despite it's garbled output.                                                                   |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Text generation   | ROBERTa | The future of Artificial Intelligence is            | Failed   | Now, like the BERT model, the ROBERTa model follows an Encoder-only transformer too. The text-generation would be better done using the decoder.      |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Fill-mask         | BERT    | the goal of generative ai is to create new content. | Success  | The Encoder-only models, with BERT included, are preferred for the Masked Language Modelling.                                                         |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Fill-mask         | BART    | The goal of Generative AI is to create new content. | Success  | This follows an Encoder-Decoder architecture....so, the result was a success.                                                                         |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Fill-mask         | ROBERTa | The goal of Generative AI is to create new content. | Success  | The Encoder-only models, with ROBERTa included, are preferred for the Masked Language Modelling.                                                      |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Q&A               | BERT    | technology, task.                                   | Success  | The encoder-only models are trained for the questions and answers generation.                                                                         |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Q&A               | BART    | a new email falls, a new email falls.               | Success  | The encoder-decoder models are capable in the generation of the questions and answers.                                                                |
------------------|---------|-----------------------------------------------------|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
Q&A               | ROBERTa | model, of.                                          | Success  | The encoder-only models are trained for the questions and answers generation.                                                                         |
